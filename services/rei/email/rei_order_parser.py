"""
REI è®¢å•HTMLè§£ææœåŠ¡
ä»REIè®¢å•é‚®ä»¶çš„HTMLå†…å®¹ä¸­æå–è®¢å•ä¿¡æ¯
"""

from bs4 import BeautifulSoup
from typing import Dict, Any, List, Optional
import re
from datetime import datetime
import traceback


class ReiOrderParser:
    """REI è®¢å•HTMLè§£æå™¨"""
    
    @staticmethod
    def parse_order_from_html(html_content: str) -> Dict[str, Any]:
        """
        ä»HTMLå†…å®¹ä¸­è§£æREIè®¢å•ä¿¡æ¯
        
        Args:
            html_content: é‚®ä»¶çš„HTMLå†…å®¹
            
        Returns:
            è§£æåçš„è®¢å•æ•°æ®å­—å…¸
        """
        try:
            soup = BeautifulSoup(html_content, 'html.parser')
            
            order_data = {
                'order_number': None,
                'order_date': None,
                'order_time': None,
                'email': None,
                'status': 'pending',
                'estimated_arrival': None,
                'delivery_status': 'not_delivered',
                'delivered_date': None,
                'scheduled_delivery_date': None,
                'amount': 0.00,
                'subtotal': 0.00,
                'shipping_fee': 0.00,
                'tax': 0.00,
                'total': 0.00,
                'paid': 0.00,
                'total_savings': 0.00,
                'shipping_name': None,
                'shipping_address': None,
                'shipping_city': None,
                'shipping_state': None,
                'shipping_zip_code': None,
                'shipping_method': 'Standard shipping',
                'billing_name': None,
                'billing_address': None,
                'billing_city': None,
                'billing_state': None,
                'billing_zip_code': None,
                'products': [],
                'gift_cards': []
            }
            
            # 1. æå–è®¢å•å·
            order_number = ReiOrderParser._extract_order_number(soup)
            if order_number:
                order_data['order_number'] = order_number
            
            # 2. æå–è®¢å•æ—¥æœŸå’Œæ—¶é—´
            order_date_info = ReiOrderParser._extract_order_date(soup)
            if order_date_info:
                order_data.update(order_date_info)
            
            # 3. æå–é¢„è®¡åˆ°è¾¾æ—¶é—´
            estimated_arrival = ReiOrderParser._extract_estimated_arrival(soup)
            if estimated_arrival:
                order_data['estimated_arrival'] = estimated_arrival
            
            # 4. æå–æ”¶è´§åœ°å€
            shipping_info = ReiOrderParser._extract_shipping_address(soup)
            if shipping_info:
                order_data.update(shipping_info)
            
            # 5. æå–é…é€æ–¹å¼
            shipping_method = ReiOrderParser._extract_shipping_method(soup)
            if shipping_method:
                order_data['shipping_method'] = shipping_method
            
            # 6. æå–è´¦å•åœ°å€
            billing_info = ReiOrderParser._extract_billing_address(soup)
            if billing_info:
                order_data.update(billing_info)
            
            # 7. æå–é‡‘é¢ä¿¡æ¯ï¼ˆå·²ç§»é™¤å•†å“ä¿¡æ¯æå–ï¼‰
            amount_info = ReiOrderParser._extract_amounts(soup)
            if amount_info:
                order_data.update(amount_info)
            
            # 9. æå–ç¤¼å“å¡ä¿¡æ¯
            gift_cards = ReiOrderParser._extract_gift_cards(soup)
            if gift_cards:
                order_data['gift_cards'] = gift_cards
            
            print(f"âœ… æˆåŠŸè§£æè®¢å•: {order_data['order_number']}")
            return order_data
            
        except Exception as e:
            print(f"âŒ è§£æè®¢å•HTMLå¤±è´¥: {e}")
            traceback.print_exc()
            return None
    
    @staticmethod
    def _extract_order_number(soup: BeautifulSoup) -> Optional[str]:
        """æå–è®¢å•å·"""
        try:
            # æŸ¥æ‰¾åŒ…å«è®¢å•å·çš„pæ ‡ç­¾
            # <p style="...font-size:20px..."> A385267303 </p>
            for p in soup.find_all('p'):
                style = p.get('style', '')
                if 'font-size:20px' in style or 'font-size: 20px' in style:
                    text = p.get_text(strip=True)
                    # éªŒè¯æ˜¯å¦ä¸ºè®¢å•å·æ ¼å¼ï¼ˆå­—æ¯+æ•°å­—ï¼‰
                    if re.match(r'^[A-Z]\d{9}$', text):
                        return text
            
            # å¤‡ç”¨æ–¹æ³•ï¼šæŸ¥æ‰¾åŒ…å«"Order date"çš„æ®µè½é™„è¿‘çš„è®¢å•å·
            for p in soup.find_all('p'):
                text = p.get_text(strip=True)
                if re.match(r'^[A-Z]\d{9}$', text):
                    return text
            
            return None
        except Exception as e:
            print(f"âš ï¸ æå–è®¢å•å·å¤±è´¥: {e}")
            return None
    
    @staticmethod
    def _extract_order_date(soup: BeautifulSoup) -> Optional[Dict]:
        """æå–è®¢å•æ—¥æœŸå’Œæ—¶é—´"""
        try:
            # æŸ¥æ‰¾åŒ…å«"Order date:"çš„pæ ‡ç­¾
            for p in soup.find_all('p'):
                text = p.get_text(strip=True)
                if 'Order date:' in text:
                    # æå–æ—¥æœŸ "Order date: 10/06/2025"
                    match = re.search(r'Order date:\s*(\d{2})/(\d{2})/(\d{4})', text)
                    if match:
                        month, day, year = match.groups()
                        order_date = f"{year}-{month}-{day}"
                        return {
                            'order_date': order_date,
                            'order_time': None  # ç•™ç©ºï¼Œä½¿ç”¨å…¶ä»–æ–¹æ³•è·å–
                        }
            
            return None
        except Exception as e:
            print(f"âš ï¸ æå–è®¢å•æ—¥æœŸå¤±è´¥: {e}")
            return None
    
    @staticmethod
    def _extract_estimated_arrival(soup: BeautifulSoup) -> Optional[str]:
        """æå–é¢„è®¡åˆ°è¾¾æ—¶é—´"""
        try:
            # æŸ¥æ‰¾åŒ…å«é¢„è®¡åˆ°è¾¾æ—¶é—´çš„pæ ‡ç­¾
            # <p style="...font-size:22px...">Fri, Oct 10</p>
            for p in soup.find_all('p'):
                style = p.get('style', '')
                if 'font-size:22px' in style or 'font-size: 22px' in style:
                    text = p.get_text(strip=True)
                    # éªŒè¯æ—¥æœŸæ ¼å¼ "Fri, Oct 10"
                    if re.match(r'^[A-Z][a-z]{2},\s+[A-Z][a-z]{2}\s+\d{1,2}$', text):
                        return text
            
            return None
        except Exception as e:
            print(f"âš ï¸ æå–é¢„è®¡åˆ°è¾¾æ—¶é—´å¤±è´¥: {e}")
            return None
    
    @staticmethod
    def _extract_shipping_address(soup: BeautifulSoup) -> Optional[Dict]:
        """æå–æ”¶è´§åœ°å€å’Œç‰©æµURL"""
        try:
            text = soup.get_text()
            
            # æ–¹æ³•1ï¼šæŸ¥æ‰¾ "Ship to:" åé¢çš„åœ°å€
            ship_to_pattern = r'Ship\s+to:\s*([^\n]+)\n([^\n]+)\n([A-Z\s]+),\s+([A-Z]{2})\s+(\d{5})'
            match = re.search(ship_to_pattern, text, re.IGNORECASE)
            if match:
                name = match.group(1).strip()
                address = match.group(2).strip()
                city = match.group(3).strip()
                state = match.group(4)
                zip_code = match.group(5)
                
                # å°è¯•æå–ç‰©æµURLï¼ˆæŸ¥æ‰¾åœ°å€ç›¸å…³çš„é“¾æ¥ï¼‰
                tracking_url = ReiOrderParser._extract_tracking_url(soup)
                
                return {
                    'shipping_name': name,
                    'shipping_address': address,
                    'shipping_city': city,
                    'shipping_state': state,
                    'shipping_zip_code': zip_code,
                    'tracking_url': tracking_url
                }
            
            # æ–¹æ³•2ï¼šæŸ¥æ‰¾åŒ…å«æ”¶è´§åœ°å€çš„pæ ‡ç­¾ï¼ˆåŸæœ‰é€»è¾‘ï¼‰
            for p in soup.find_all('p'):
                # æŸ¥æ‰¾åŒ…å«å¤šè¡Œåœ°å€çš„æ®µè½
                if '<br>' in str(p) or '<br/>' in str(p):
                    # è·å–æ‰€æœ‰æ–‡æœ¬è¡Œ
                    lines = [line.strip() for line in p.stripped_strings if line.strip()]
                    
                    if len(lines) >= 3:
                        # ç¬¬ä¸€è¡Œï¼šå§“å
                        name = lines[0]
                        
                        # æŸ¥æ‰¾å·å’Œé‚®ç¼–æ‰€åœ¨çš„è¡Œï¼ˆæ ¼å¼ï¼šCITY, STATE ZIPCODEï¼‰
                        for i, line in enumerate(lines):
                            # åŒ¹é…æ ¼å¼ï¼šWHITEFISH, MT 59937 æˆ– San Leandro, CA 94577
                            match = re.search(r'([A-Za-z\s]+),\s+([A-Z]{2})\s+(\d{5})', line)
                            if match:
                                city, state, zip_code = match.groups()
                                # åœ°å€æ˜¯ä¸­é—´çš„è¡Œ
                                address_parts = lines[1:i]
                                address = ' '.join(address_parts) if address_parts else lines[1] if len(lines) > 1 else ''
                                
                                # éªŒè¯æ˜¯å¦ä¸ºæ”¶è´§åœ°å€ï¼ˆæ£€æŸ¥æ˜¯å¦åœ¨ "Ship to" é™„è¿‘ï¼‰
                                p_text = p.get_text()
                                # æŸ¥æ‰¾å‰é¢çš„æ–‡æœ¬
                                all_p_tags = soup.find_all('p')
                                p_index = all_p_tags.index(p) if p in all_p_tags else -1
                                
                                if p_index >= 0:
                                    # æ£€æŸ¥å‰é¢5ä¸ªpæ ‡ç­¾æ˜¯å¦åŒ…å« "Ship to"
                                    prev_text = ' '.join([all_p_tags[j].get_text() for j in range(max(0, p_index-5), p_index)])
                                    if 'ship' in prev_text.lower() or p_index < 15:
                                        # å°è¯•æå–ç‰©æµURL
                                        tracking_url = ReiOrderParser._extract_tracking_url(soup)
                                        
                                        return {
                                            'shipping_name': name,
                                            'shipping_address': address,
                                            'shipping_city': city.strip(),
                                            'shipping_state': state,
                                            'shipping_zip_code': zip_code,
                                            'tracking_url': tracking_url
                                        }
            
            print(f"  âš ï¸ æœªæ‰¾åˆ°æ”¶è´§åœ°å€")
            return None
        except Exception as e:
            print(f"âŒ æå–æ”¶è´§åœ°å€å¤±è´¥: {e}")
            traceback.print_exc()
            return None
    
    @staticmethod
    def _extract_tracking_url(soup: BeautifulSoup) -> Optional[str]:
        """æå–ç‰©æµè¿½è¸ªURLï¼ˆä»åœ°å€é“¾æ¥ä¸­æå–ï¼‰"""
        try:
            # æŸ¥æ‰¾æ‰€æœ‰aæ ‡ç­¾
            for a in soup.find_all('a'):
                href = a.get('href', '')
                # æŸ¥æ‰¾Google Mapsé“¾æ¥ï¼ˆé€šå¸¸æ˜¯åœ°å€é“¾æ¥ï¼‰
                if 'google.com/maps' in href or 'maps.google.com' in href:
                    # æå–åŸå§‹URLï¼ˆå»é™¤Gmailé‡å®šå‘ï¼‰
                    if 'data-saferedirecturl' in a.attrs:
                        safe_url = a.get('data-saferedirecturl', '')
                        # ä» data-saferedirecturl ä¸­æå–çœŸå®URL
                        # æ ¼å¼: https://www.google.com/url?q=REAL_URL&source=...
                        if '?q=' in safe_url:
                            import urllib.parse
                            parsed = urllib.parse.urlparse(safe_url)
                            query_params = urllib.parse.parse_qs(parsed.query)
                            if 'q' in query_params:
                                real_url = query_params['q'][0]
                                print(f"  ğŸ“ æ‰¾åˆ°ç‰©æµURL: {real_url}")
                                return real_url
                    
                    # å¦‚æœæ²¡æœ‰ data-saferedirecturlï¼Œç›´æ¥è¿”å› href
                    print(f"  ğŸ“ æ‰¾åˆ°ç‰©æµURL: {href}")
                    return href
            
            print(f"  âš ï¸ æœªæ‰¾åˆ°ç‰©æµURL")
            return None
        except Exception as e:
            print(f"âš ï¸ æå–ç‰©æµURLå¤±è´¥: {e}")
            return None
    
    @staticmethod
    def _extract_shipping_method(soup: BeautifulSoup) -> Optional[str]:
        """æå–é…é€æ–¹å¼"""
        try:
            # æŸ¥æ‰¾åŒ…å«é…é€æ–¹å¼çš„pæ ‡ç­¾ï¼ˆé€šå¸¸æ˜¯æ–œä½“ï¼‰
            for p in soup.find_all('p'):
                style = p.get('style', '')
                if 'font-style:italic' in style or 'font-style: italic' in style:
                    text = p.get_text(strip=True)
                    if 'shipping' in text.lower():
                        return text
            
            return None
        except Exception as e:
            print(f"âš ï¸ æå–é…é€æ–¹å¼å¤±è´¥: {e}")
            return None
    
    @staticmethod
    def _extract_billing_address(soup: BeautifulSoup) -> Optional[Dict]:
        """æå–è´¦å•åœ°å€"""
        try:
            text = soup.get_text()
            
            # æ–¹æ³•1ï¼šæŸ¥æ‰¾ "Billing address:" åé¢çš„åœ°å€
            billing_pattern = r'Billing\s+address:\s*([^\n]+)\n([^\n]+)\n([A-Za-z\s]+),\s+([A-Z]{2})\s+(\d{5})'
            match = re.search(billing_pattern, text, re.IGNORECASE)
            if match:
                name = match.group(1).strip()
                address = match.group(2).strip()
                city = match.group(3).strip()
                state = match.group(4)
                zip_code = match.group(5)
                
                return {
                    'billing_name': name,
                    'billing_address': address,
                    'billing_city': city,
                    'billing_state': state,
                    'billing_zip_code': zip_code
                }
            
            # æ–¹æ³•2ï¼šæŸ¥æ‰¾åŒ…å«è´¦å•åœ°å€çš„pæ ‡ç­¾ï¼ˆé€šå¸¸åœ¨é‚®ä»¶ååŠéƒ¨åˆ†ï¼‰
            all_paragraphs = soup.find_all('p')
            
            for i, p in enumerate(all_paragraphs):
                # æŸ¥æ‰¾åŒ…å«å¤šè¡Œåœ°å€çš„æ®µè½
                if '<br>' in str(p) or '<br/>' in str(p):
                    lines = [line.strip() for line in p.stripped_strings if line.strip()]
                    
                    if len(lines) >= 3:
                        name = lines[0]
                        
                        # æŸ¥æ‰¾å·å’Œé‚®ç¼–
                        for j, line in enumerate(lines):
                            match = re.search(r'([A-Za-z\s]+),\s+([A-Z]{2})\s+(\d{5})', line)
                            if match:
                                city, state, zip_code = match.groups()
                                address_parts = lines[1:j]
                                address = ' '.join(address_parts) if address_parts else lines[1] if len(lines) > 1 else ''
                                
                                # éªŒè¯æ˜¯å¦ä¸ºè´¦å•åœ°å€ï¼ˆåœ¨é‚®ä»¶ååŠéƒ¨åˆ†æˆ–åŒ…å«billingå…³é”®è¯ï¼‰
                                prev_text = ' '.join([all_paragraphs[k].get_text() for k in range(max(0, i-3), i)])
                                if 'billing' in prev_text.lower() or i > len(all_paragraphs) // 2:
                                    return {
                                        'billing_name': name,
                                        'billing_address': address,
                                        'billing_city': city.strip(),
                                        'billing_state': state,
                                        'billing_zip_code': zip_code
                                    }
            
            print(f"  âš ï¸ æœªæ‰¾åˆ°è´¦å•åœ°å€")
            return None
        except Exception as e:
            print(f"âŒ æå–è´¦å•åœ°å€å¤±è´¥: {e}")
            traceback.print_exc()
            return None
    
    @staticmethod
    def _extract_amounts(soup: BeautifulSoup) -> Optional[Dict]:
        """æå–é‡‘é¢ä¿¡æ¯"""
        try:
            amounts = {
                'subtotal': 0.00,
                'shipping_fee': 0.00,
                'tax': 0.00,
                'total': 0.00,
                'total_savings': 0.00
            }
            
            # æŸ¥æ‰¾åŒ…å«é‡‘é¢çš„æ–‡æœ¬
            text = soup.get_text()
            
            # æå–å°è®¡
            match = re.search(r'Subtotal[:\s]+\$?([\d,]+\.\d{2})', text, re.IGNORECASE)
            if match:
                amounts['subtotal'] = float(match.group(1).replace(',', ''))
            
            # æå–è¿è´¹
            match = re.search(r'Shipping[:\s]+\$?([\d,]+\.\d{2})', text, re.IGNORECASE)
            if match:
                amounts['shipping_fee'] = float(match.group(1).replace(',', ''))
            
            # æå–ç¨è´¹
            match = re.search(r'Tax[:\s]+\$?([\d,]+\.\d{2})', text, re.IGNORECASE)
            if match:
                amounts['tax'] = float(match.group(1).replace(',', ''))
            
            # æå–æ€»è®¡
            match = re.search(r'Total[:\s]+\$?([\d,]+\.\d{2})', text, re.IGNORECASE)
            if match:
                amounts['total'] = float(match.group(1).replace(',', ''))
                amounts['amount'] = amounts['total']
            
            # æå–èŠ‚çœé‡‘é¢
            match = re.search(r'(?:You saved|Total savings)[:\s]+\$?([\d,]+\.\d{2})', text, re.IGNORECASE)
            if match:
                amounts['total_savings'] = float(match.group(1).replace(',', ''))
            
            return amounts
        except Exception as e:
            print(f"âš ï¸ æå–é‡‘é¢ä¿¡æ¯å¤±è´¥: {e}")
            return None
    
    @staticmethod
    def _extract_gift_cards(soup: BeautifulSoup) -> List[float]:
        """æå–ç¤¼å“å¡é‡‘é¢"""
        try:
            gift_cards = []
            
            # æŸ¥æ‰¾åŒ…å«ç¤¼å“å¡çš„æ–‡æœ¬
            text = soup.get_text()
            
            # æŸ¥æ‰¾ç¤¼å“å¡é‡‘é¢ï¼ˆæ ¼å¼ï¼š$27.46, $52.37, $60.00ï¼‰
            matches = re.findall(r'Gift\s+card[:\s]+\$?([\d,]+\.\d{2})', text, re.IGNORECASE)
            for match in matches:
                amount = float(match.replace(',', ''))
                gift_cards.append(amount)
            
            return gift_cards
        except Exception as e:
            print(f"âš ï¸ æå–ç¤¼å“å¡ä¿¡æ¯å¤±è´¥: {e}")
            return []
